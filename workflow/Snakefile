from pathlib import Path


configfile: "config/config.yaml"


config["OUTPUT_DIR"] = str(Path(config["OUTPUT_DIR"]).resolve())


rule all:
    input:
        f"{config['OUTPUT_DIR']}/upload/test-data.tgz",


rule make_upload_archive:
    output:
        f"{config['OUTPUT_DIR']}/upload/test-data.tgz",
    input:
        f"{config['OUTPUT_DIR']}/results/genome/dna.fa",
        f"{config['OUTPUT_DIR']}/results/genome/dna.gtf",
        expand(
            f"{config['OUTPUT_DIR']}/results/reads/{{source}}/{{run_type}}/Undetermined_S0_{{read}}_001.fastq.gz",
            source=["fastq_from_aviti", "fastq_from_bcl"],
            run_type=["one_run/run1", "two_runs/run1", "two_runs/run2"],
            read=["R1", "R2"],
        ),
        expand(
            f"{config['OUTPUT_DIR']}/results/reads/bcl/{{run_type}}/.done",
            run_type=["one_run/run1", "two_runs/run1", "two_runs/run2"],
        ),
    params:
        results_dir=f"{config['OUTPUT_DIR']}/results",
    log:
        f"{config['OUTPUT_DIR']}/logs/make_upload_archive.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        cd {params.results_dir}
        tar -czvf {output}  *
        """


rule make_bcl_reads:
    wildcard_constraints:
        run_type="one_run/run1|two_runs/run1|two_runs/run2",
    input:
        r1=f"{config['OUTPUT_DIR']}/results/reads/fastq_from_bcl/{{run_type}}/Undetermined_S0_R1_001.fastq.gz",
        r2=f"{config['OUTPUT_DIR']}/results/reads/fastq_from_bcl/{{run_type}}/Undetermined_S0_R2_001.fastq.gz",
    output:
        dir=directory(f"{config['OUTPUT_DIR']}/results/reads/bcl/{{run_type}}"),
        touch=touch(f"{config['OUTPUT_DIR']}/results/reads/bcl/{{run_type}}/.done"),
    params:
        roundtrip_dir=f"{config['OUTPUT_DIR']}/resources/reads/fastq_from_bcl/{{run_type}}/roundtrip",
    log:
        f"{config['OUTPUT_DIR']}/logs/make_bcl_reads_{{run_type}}.log",
    conda:
        "envs/fastq2bcl.yaml"
    shell:
        """
        # confirm we are using our fork of fastq2bcl
        which fastq2bcl &> {log} 
        fastq2bcl --version &>> {log}

        # convert fastq to bcl
        mkdir -p {output.dir}
        fastq2bcl -r1 {input.r1} -r2 {input.r2} -o {output.dir} &>> {log} && touch {output.touch}

        # convert the generated bcl files back to fastq to verify integrity
        mkdir -p {params.roundtrip_dir}
        echo -e "[DATA]\nLane,Sample_ID,Sample_Name,index,index2\n,fake,fake,NNNNNNNNNN,NNNNNNNNNN" > {params.roundtrip_dir}/fake.csv
        bcl2fastq \
            --barcode-mismatches 1 \
            --ignore-missing-positions \
            --ignore-missing-controls \
            --ignore-missing-filter \
            --ignore-missing-bcls \
            --no-lane-splitting \
            --minimum-trimmed-read-length 15 \
            --mask-short-adapter-reads 15 \
            -R {output.dir}/YYMMDD_VH00821_0006_AACCCKLM5 \
            --sample-sheet {params.roundtrip_dir}/fake.csv \
            --output-dir {params.roundtrip_dir} \
            &>> {log}

        # compare original and roundtrip fastq files
        diff <(zcat {input.r1}) <(zcat {params.roundtrip_dir}/Undetermined_S0_R1_001.fastq.gz) &>> {log} 
        diff <(zcat {input.r2}) <(zcat {params.roundtrip_dir}/Undetermined_S0_R2_001.fastq.gz) &>> {log} 
        """


rule process_fastq:
    wildcard_constraints:
        fastq_source="fastq_from_aviti|fastq_from_bcl",
    input:
        r1=f"{config['READS_DIR']}/{{fastq_source}}/Undetermined_S0_R1_001.fastq.gz",
        r2=f"{config['READS_DIR']}/{{fastq_source}}/Undetermined_S0_R2_001.fastq.gz",
    output:
        r1=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/one_run/run1/Undetermined_S0_R1_001.fastq.gz",
        r2=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/one_run/run1/Undetermined_S0_R2_001.fastq.gz",
        run1r1=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/two_runs/run1/Undetermined_S0_R1_001.fastq.gz",
        run1r2=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/two_runs/run1/Undetermined_S0_R2_001.fastq.gz",
        run2r1=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/two_runs/run2/Undetermined_S0_R1_001.fastq.gz",
        run2r2=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/two_runs/run2/Undetermined_S0_R2_001.fastq.gz",
    params:
        output_dir1=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/one_run",
        output_dir2=f"{config['OUTPUT_DIR']}/results/reads/{{fastq_source}}/two_runs",
        split_dir=f"{config['OUTPUT_DIR']}/resources/reads/{{fastq_source}}/split",
    log:
        f"{config['OUTPUT_DIR']}/logs/process_fastq_from_{{fastq_source}}.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        # copy for single run
        mkdir -p {params.output_dir1}/run1
        cp {input.r1} {output.r1}
        cp {input.r2} {output.r2}
        
        # split in half to make two runs with same combined reads 
        mkdir -p {params.output_dir2}/run1
        mkdir -p {params.output_dir2}/run2
        mkdir -p {params.split_dir}
        seqkit split2 -p 2 -1 {input.r1} -2 {input.r2} -e .gz -O {params.split_dir} 2>> {log}
        mv {params.split_dir}/Undetermined_S0_R1_001.part_001.fastq.gz {output.run1r1}
        mv {params.split_dir}/Undetermined_S0_R2_001.part_001.fastq.gz {output.run1r2}
        mv {params.split_dir}/Undetermined_S0_R1_001.part_002.fastq.gz {output.run2r1}
        mv {params.split_dir}/Undetermined_S0_R2_001.part_002.fastq.gz {output.run2r2}
        """


rule download_genome_fasta:
    output:
        f"{config['OUTPUT_DIR']}/resources/genome/dna.fa",
    params:
        url=config["GENOME_FASTA_URL"],
    log:
        f"{config['OUTPUT_DIR']}/logs/download_genome_fasta.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        wget -q -O - {params.url} | gunzip > {output} 2> {log}
        """


rule download_genome_gtf:
    output:
        f"{config['OUTPUT_DIR']}/resources/genome/dna.gtf",
    params:
        url=config["GENOME_GTF_URL"],
    log:
        f"{config['OUTPUT_DIR']}/logs/download_genome_gtf.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        wget -q -O - {params.url} | gunzip > {output} 2> {log}
        """


rule index_genome_fasta:
    input:
        f"{config['OUTPUT_DIR']}/resources/genome/dna.fa",
    output:
        f"{config['OUTPUT_DIR']}/resources/genome/dna.fa.fai",
    log:
        f"{config['OUTPUT_DIR']}/logs/index_genome_fasta.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        samtools faidx {input} 2> {log}
        """


rule extract_genome_fasta:
    input:
        fa=f"{config['OUTPUT_DIR']}/resources/genome/dna.fa",
        fai=f"{config['OUTPUT_DIR']}/resources/genome/dna.fa.fai",
    output:
        f"{config['OUTPUT_DIR']}/results/genome/dna.fa",
    params:
        chr=config["CHR"],
    log:
        f"{config['OUTPUT_DIR']}/logs/extract_genome_fasta.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        samtools faidx {input.fa} {params.chr} > {output} 2> {log}
        """


rule extract_genome_gtf:
    input:
        f"{config['OUTPUT_DIR']}/resources/genome/dna.gtf",
    output:
        f"{config['OUTPUT_DIR']}/results/genome/dna.gtf",
    params:
        chr=config["CHR"],
    log:
        f"{config['OUTPUT_DIR']}/logs/extract_genome_gtf.log",
    conda:
        "envs/tools.yaml"
    shell:
        """
        gffread {input} -r {params.chr} -T -o {output} 2> {log}
        """
